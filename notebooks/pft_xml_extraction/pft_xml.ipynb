{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9e55770",
   "metadata": {},
   "source": [
    "# üß≠ Overview\n",
    "This notebook processes XML-based lung function data to identify airway obstruction using morphological features and machine learning. \n",
    "\n",
    "**Goals:**\n",
    "- Load and parse XML-format lung function test reports\n",
    "- Extract relevant spirometry parameters\n",
    "- Identify patterns consistent with airway obstruction\n",
    "- Prepare data for ECG-linked ML classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01aca5e3",
   "metadata": {},
   "source": [
    "# üìÅ Setup and Imports\n",
    "\n",
    "### üì¶ What does `from lxml import etree` do?\n",
    "\n",
    "This line imports the `etree` module from the `lxml` library, which is a powerful and fast XML parser.\n",
    "\n",
    "‚úÖ **Why use `lxml.etree` instead of Python‚Äôs built-in `xml.etree.ElementTree`?**\n",
    "\n",
    "- Much **faster** and more **robust**, especially with large or complex XML files.\n",
    "- Supports **XPath** expressions, allowing flexible and efficient queries.\n",
    "- Handles **namespaces**, **comments**, and **malformed XML** more gracefully.\n",
    "- Often used in scientific and biomedical data processing where XML schemas are complex.\n",
    "\n",
    "üí° In this project, we use `etree` to:\n",
    "- Parse XML-based lung function test reports\n",
    "- Navigate the tree-like structure to extract values like FEV1, FVC, etc.\n",
    "- Convert structured XML data into tabular format for ML processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6df004",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from lxml import etree\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb069f5",
   "metadata": {},
   "source": [
    "# üì¶ Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e038ec6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up base folders\n",
    "base_path = Path.cwd()\n",
    "input_folder = base_path / \"input\"\n",
    "output_folder = base_path / \"output\"\n",
    "\n",
    "xml_files = list(input_folder.glob(\"*.xml\"))\n",
    "print(f\"Found {len(xml_files)} .xml file(s) for extraction:\")\n",
    "for f in xml_files:\n",
    "    print(\" -\", f.name)\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8685735",
   "metadata": {},
   "source": [
    "# üìÑ XML Parsing\n",
    "### üìÑ Understanding the XML File Structure\n",
    "\n",
    "We assume you have downloaded the XML files directly from the lung function lab computer.  \n",
    "These originate from **COSMED** hardware systems, using the **OMNIA** software suite for pulmonary diagnostics.  \n",
    "The XML schema is proprietary to COSMED's OMNIA software. It is not a public or standardized format and may change in future software updates.  \n",
    "Our current files follow a consistent structure designed to encode both subject demographics and full pulmonary test results.\n",
    "\n",
    "Each file contains three main sections:\n",
    "\n",
    "- **Subject**: Includes the patient's ID, name, date of birth (formatted as `YYYYMMDD000000` within the `ExtendedInfo` attribute), gender, and ethnicity. This is essential for linking test results to individuals. Data is therefore kept within the hospital's ecosystem and handled in accordance with hospital policies and the Ethics approval for this study.\n",
    "  \n",
    "- **Visit**: Encapsulates clinical metadata about the testing encounter such as visit date, smoking history (e.g., pack-years, cigarettes/day), comorbidities (e.g., diabetes), anthropometric measurements (height/weight), and the referring physician.\n",
    "\n",
    "- **Test**: Nested inside each Visit, this section may contain multiple test records (e.g., Spirometry, MVV). Each Test node includes:\n",
    "  - `TestType`: e.g., \"Spirometry\"\n",
    "  - `AdditionalData`: comprising:\n",
    "    - **Parameter** nodes for scalar outputs like FEV1, FVC, PEF, etc.\n",
    "    - **Graph** nodes (e.g., `Graph1`) with digitized waveform data like flow-volume loops in `<Point X=\"...\" Y=\"...\"/>` format, along with metadata like sampling interval and axis labels.\n",
    "\n",
    "Importantly, **multiple test attempts may be present within the same visit**‚Äîfor example, repeated spirometry blows. In this notebook, we extract and save **only the best effort**, as defined by COSMED‚Äôs OMNIA software, which is consistently presented as the **first** or **only preserved** entry in the XML.\n",
    "\n",
    "This rich XML structure allows us to extract both discrete measurements and waveform data for downstream analysis such as obstruction classification and waveform morphology learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad1f7cb",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è The XML Extraction and Processing Pipeline\n",
    "\n",
    "This section performs the full end-to-end extraction of structured and graphical data from each XML file. The goal is to convert each patient test file into both a JSON format (for flexible structured access) and a flattened CSV row (for easy analysis and model training).\n",
    "\n",
    "Here's what happens step-by-step:\n",
    "\n",
    "1. **Graph Data Extraction**  \n",
    "   `extract_graph()` processes flow-volume loop data inside each `Graph` element. It reads:\n",
    "   - X and Y axis labels (e.g., `\"V (L)\"`, `\"F (L/s)\"`)\n",
    "   - Sampling interval and point count\n",
    "   - A list of 2D coordinates from `<Point X=\"...\" Y=\"...\"/>`, stored as a list of [x, y] pairs.\n",
    "\n",
    "2. **Subject and Visit Metadata**  \n",
    "   `parse_xml_to_dict()` extracts:\n",
    "   - Patient information like ID, name, DOB, gender, ethnicity\n",
    "   - Visit-level metadata: smoking status, diabetes, height/weight, physician, technician, etc.\n",
    "   - An empty `Tests` list, to be populated in the next step.\n",
    "\n",
    "3. **Test Parsing and Selection**  \n",
    "   `add_tests_from_xml()` finds all tests in the visit and:\n",
    "   - Captures the test type and ID\n",
    "   - Appends all scalar parameters (like FEV1, FVC) into a list\n",
    "   - Extracts waveform data from any `Graph` elements using `extract_graph()`\n",
    "\n",
    "   ‚ö†Ô∏è Note: If multiple tests of the same type are present (e.g., multiple spirometry blows), **all are stored**, but **only the best loop is saved in the CSV**, as described below.\n",
    "\n",
    "4. **Flattening for CSV Output**  \n",
    "   `flatten_dict_to_row()` converts the structured dictionary into a flat row for DataFrame use:\n",
    "   - All core metadata and scalar test results are unfolded into named columns\n",
    "   - The **best flow-volume loop** is identified by matching `X = \"V (L)\"` and `Y = \"F (L/s)\"` in `Graph1`, and saved under a `FlowVolumeLoop` column\n",
    "\n",
    "5. **Main Processing Loop**  \n",
    "   For each `.xml` file:\n",
    "   - It parses the XML using `lxml.etree`\n",
    "   - Builds the structured data dictionary\n",
    "   - Saves a full `.json` file with all nested metadata and waveform points\n",
    "   - Flattens the data into a single-row `.csv` file for analysis\n",
    "   - Appends the output paths to `saved_json_paths` for summary display\n",
    "\n",
    "This modular design allows flexible reuse of the structured `.json` format while supporting tabular workflows with the `.csv` outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf13019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_graph(graph_elem):\n",
    "    return {\n",
    "        \"X\": graph_elem.attrib.get(\"X\"),\n",
    "        \"Y\": graph_elem.attrib.get(\"Y\"),\n",
    "        \"Count\": int(graph_elem.attrib.get(\"Count\", \"0\")),\n",
    "        \"SamplingInterval\": float(graph_elem.attrib.get(\"SamplingInterval\", \"0\")),\n",
    "        \"Points\": [\n",
    "            [float(p.attrib[\"X\"]), float(p.attrib[\"Y\"])]\n",
    "            for p in graph_elem.iter(\"Point\")\n",
    "            if \"X\" in p.attrib and \"Y\" in p.attrib\n",
    "        ]\n",
    "    }\n",
    "def parse_xml_to_dict(root):\n",
    "    subject = root.find(\"Subject\")\n",
    "    visit = subject.find(\"Visit\")\n",
    "    return {\n",
    "        \"Subject\": {\n",
    "            \"SubjectID\": subject.findtext(\"ID\"),\n",
    "            \"FirstName\": subject.findtext(\"FirstName\"),\n",
    "            \"LastName\": subject.findtext(\"LastName\"),\n",
    "            \"DOB\": subject.find(\"DayOfBirth\").attrib.get(\"ExtendedInfo\")[:8],\n",
    "            \"Gender\": subject.find(\"GenderID\").attrib.get(\"ExtendedInfo\"),\n",
    "            \"Ethnicity\": subject.find(\"ethnicID\").attrib.get(\"ExtendedInfo\"),\n",
    "        },\n",
    "        \"Visit\": {\n",
    "            \"RecordID\": visit.findtext(\"RecordID\"),\n",
    "            \"CreatedOn\": visit.find(\"CreatedOn\").attrib.get(\"ExtendedInfo\")[:8],\n",
    "            \"Smoker\": visit.findtext(\"Smoker\"),\n",
    "            \"CigarettesPerDay\": visit.findtext(\"CigDie\"),\n",
    "            \"SmokeYears\": visit.findtext(\"SmokeYears\"),\n",
    "            \"SmokeWhat\": visit.findtext(\"SmokeWhat\"),\n",
    "            \"NonSmokeYears\": visit.findtext(\"NonSmokeYears\"),\n",
    "            \"Height_cm\": visit.findtext(\"Height\"),\n",
    "            \"Weight_kg\": visit.findtext(\"Weight\"),\n",
    "            \"Technician\": visit.findtext(\"Technician\"),\n",
    "            \"Physician\": visit.findtext(\"Physician\"),\n",
    "            \"ReferringPhysician\": visit.findtext(\"ReferringPhysician\"),\n",
    "            \"VisitReason\": visit.findtext(\"VisitReason\"),\n",
    "            \"Diabetes\": visit.findtext(\"Diabetes\"),\n",
    "            \"Tests\": []\n",
    "        }\n",
    "    }\n",
    "\n",
    "def add_tests_from_xml(data_dict, visit_elem):\n",
    "    for test in visit_elem.findall(\"Test\"):\n",
    "        test_type_elem = test.find(\"TestType\")\n",
    "        test_type = test_type_elem.attrib.get(\"ExtendedInfo\") if test_type_elem is not None else None\n",
    "        test_id = test_type_elem.text if test_type_elem is not None else None\n",
    "\n",
    "        test_record = {\n",
    "            \"TestType\": test_type,\n",
    "            \"TestID\": test_id,\n",
    "            \"Parameters\": [],\n",
    "            \"Graphs\": {}\n",
    "        }\n",
    "\n",
    "        additional_data = test.find(\"AdditionalData\")\n",
    "        if additional_data is not None:\n",
    "            for param in additional_data.iter(\"Parameter\"):\n",
    "                test_record[\"Parameters\"].append(dict(param.attrib))\n",
    "            for graph in additional_data:\n",
    "                if graph.tag.startswith(\"Graph\"):\n",
    "                    test_record[\"Graphs\"][graph.tag] = extract_graph(graph)\n",
    "\n",
    "        data_dict[\"Visit\"][\"Tests\"].append(test_record)\n",
    "\n",
    "def flatten_dict_to_row(data_dict):\n",
    "    subject = data_dict[\"Subject\"]\n",
    "    visit = data_dict[\"Visit\"]\n",
    "    row = {\n",
    "        \"SubjectID\": subject.get(\"SubjectID\"),\n",
    "        \"FirstName\": subject.get(\"FirstName\"),\n",
    "        \"LastName\": subject.get(\"LastName\"),\n",
    "        \"DOB\": subject.get(\"DOB\"),\n",
    "        \"Gender\": subject.get(\"Gender\"),\n",
    "        \"Ethnicity\": subject.get(\"Ethnicity\"),\n",
    "        \"VisitRecordID\": visit.get(\"RecordID\"),\n",
    "        \"VisitDate\": visit.get(\"CreatedOn\"),\n",
    "        \"Smoker\": visit.get(\"Smoker\"),\n",
    "        \"CigarettesPerDay\": visit.get(\"CigarettesPerDay\"),\n",
    "        \"SmokeYears\": visit.get(\"SmokeYears\"),\n",
    "        \"SmokeWhat\": visit.get(\"SmokeWhat\"),\n",
    "        \"NonSmokeYears\": visit.get(\"NonSmokeYears\"),\n",
    "        \"Height_cm\": visit.get(\"Height_cm\"),\n",
    "        \"Weight_kg\": visit.get(\"Weight_kg\"),\n",
    "        \"Technician\": visit.get(\"Technician\"),\n",
    "        \"Physician\": visit.get(\"Physician\"),\n",
    "        \"ReferringPhysician\": visit.get(\"ReferringPhysician\"),\n",
    "        \"VisitReason\": visit.get(\"VisitReason\"),\n",
    "        \"Diabetes\": visit.get(\"Diabetes\"),\n",
    "    }\n",
    "\n",
    "    for test in visit.get(\"Tests\", []):\n",
    "        test_prefix = test.get(\"TestType\", \"Unknown\").replace(\" \", \"_\")\n",
    "        for param in test.get(\"Parameters\", []):\n",
    "            name = param.get(\"Name\", \"Unnamed\").replace(\" \", \"_\")\n",
    "            for k, v in param.items():\n",
    "                if k != \"Name\":\n",
    "                    col = f\"{test_prefix}_{name}_{k}\".replace(\" \", \"_\")\n",
    "                    row[col] = v\n",
    "        for gname, gdata in test.get(\"Graphs\", {}).items():\n",
    "            if gdata.get(\"X\") == \"V (L)\" and gdata.get(\"Y\") == \"F (L/s)\" and gdata.get(\"Points\"):\n",
    "                row[\"FlowVolumeLoop\"] = gdata[\"Points\"]\n",
    "                break\n",
    "    return row\n",
    "\n",
    "# ---------- MAIN LOOP ----------\n",
    "saved_json_paths = []\n",
    "for xml_file in xml_files:\n",
    "    print(f\"üìÇ Processing: {xml_file.name}\")\n",
    "    \n",
    "    # Parse and build XML tree\n",
    "    tree = etree.parse(str(xml_file))\n",
    "    root = tree.getroot()\n",
    "    visit_elem = root.find(\".//Visit\")\n",
    "\n",
    "    # Build structured dict from Subject + Visit\n",
    "    data_dict = parse_xml_to_dict(root)\n",
    "\n",
    "    # Add Tests + Graphs to the same dict (in-place)\n",
    "    add_tests_from_xml(data_dict, visit_elem)\n",
    "\n",
    "    # ‚úÖ Save JSON per patient\n",
    "    json_path = output_folder / f\"{xml_file.stem.replace(' ', '_')}_extracted.json\"\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data_dict, f, indent=2)\n",
    "    saved_json_paths.append(json_path)\n",
    "    print(f\" - ‚úÖ JSON saved to: {json_path}\")\n",
    "\n",
    "    # ‚úÖ Flatten and save CSV per patient\n",
    "    row = flatten_dict_to_row(data_dict)\n",
    "    df = pd.DataFrame([row])\n",
    "    csv_path = output_folder / f\"{xml_file.stem.replace(' ', '_')}_extracted.csv\"\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\" - ‚úÖ CSV saved to: {csv_path}\")\n",
    "\n",
    "print(\"\\nüì¶ Summary: The following JSON files were saved in the list <saved_json_paths> :\")\n",
    "for path in saved_json_paths:\n",
    "    print(f\"  ‚Ä¢ {path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3508a0",
   "metadata": {},
   "source": [
    "# üîç Review, Visualisation and Classification\n",
    "\n",
    "This section reviews the extracted JSON files for each patient test, displaying subject and test details, plotting the flow-volume curve (if available), and classifying the presence and severity of airway obstruction.\n",
    "\n",
    "The pipeline performs the following steps:\n",
    "\n",
    "1. **Load Extracted JSON**  \n",
    "   For each previously saved `.json` file, the script loads structured patient and visit data into memory.\n",
    "\n",
    "2. **Display Visit and Subject Metadata**  \n",
    "   Using predefined field maps (`SUBJECT_FIELDS_MAP`, `VISIT_FIELDS_MAP`), the script prints demographic details (e.g., gender, smoking history, height/weight) and visit details (e.g., technician, physician, reason for test).\n",
    "\n",
    "3. **Group Parameters by Test Type**  \n",
    "   All parameters from each test are grouped into clinically meaningful categories:\n",
    "   - **Spirometry**: e.g., FEV1, FVC, FEV1/FVC, PEF\n",
    "   - **Lung Volumes**: e.g., TLC, RV, VC\n",
    "   - **Diffusion**: e.g., DLCO, VA, KCO\n",
    "   - **Other**: any unclassified metrics\n",
    "\n",
    "4. **Display Parameters in Table Format**  \n",
    "   Parameters in each group are printed in a neat, aligned table showing:\n",
    "   - Raw value, units, predicted value\n",
    "   - Percent predicted (% predicted), Z-score\n",
    "   - LLN and ULN (Lower/Upper Limits of Normal)\n",
    "\n",
    "5. **Extract and Plot Flow-Volume Loop**  \n",
    "   If a digitised flow-volume curve is available (i.e., X-axis is `\"V (L)\"` and Y-axis is `\"F (L/s)\"`), it is plotted using matplotlib and saved as a `.png` file.\n",
    "\n",
    "6. **Classify Obstruction Using GOLD Criteria**  \n",
    "   - If the **FEV1/FVC ratio is ‚â•70%**, the test is classified as **\"No Obstruction\"**.\n",
    "   - If **<70%**, the GOLD stage is determined using % predicted FEV1:\n",
    "     - **GOLD Stage 1**: ‚â•80%\n",
    "     - **GOLD Stage 2**: 50‚Äì79%\n",
    "     - **GOLD Stage 3**: 30‚Äì49%\n",
    "     - **GOLD Stage 4**: <30%\n",
    "   - A brief note with the GOLD classification thresholds is printed alongside the result.\n",
    "\n",
    "This section allows manual inspection and verification of the extracted data, visual confirmation of waveform quality, and automatic rule-based classification of obstructive lung disease severity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd18d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Field mappings for display\n",
    "SUBJECT_FIELDS_MAP = {\n",
    "    \"SubjectID\": (\"Subject\", \"SubjectID\"),\n",
    "    \"FirstName\": (\"Subject\", \"FirstName\"),\n",
    "    \"LastName\": (\"Subject\", \"LastName\"),\n",
    "    \"DOB\": (\"Subject\", \"DOB\"),\n",
    "    \"Gender\": (\"Subject\", \"Gender\"),\n",
    "    \"Ethnicity\": (\"Subject\", \"Ethnicity\"),\n",
    "    \"Smoker\": (\"Visit\", \"Smoker\"),\n",
    "    \"CigarettesPerDay\": (\"Visit\", \"CigarettesPerDay\"),\n",
    "    \"SmokeYears\": (\"Visit\", \"SmokeYears\"),\n",
    "    \"SmokeWhat\": (\"Visit\", \"SmokeWhat\"),\n",
    "    \"NonSmokeYears\": (\"Visit\", \"NonSmokeYears\"),\n",
    "    \"Height_cm\": (\"Visit\", \"Height_cm\"),\n",
    "    \"Weight_kg\": (\"Visit\", \"Weight_kg\"),\n",
    "    \"Diabetes\": (\"Visit\", \"Diabetes\"),\n",
    "}\n",
    "\n",
    "VISIT_FIELDS_MAP = {\n",
    "    \"RecordID\": (\"Visit\", \"RecordID\"),\n",
    "    \"CreatedOn\": (\"Visit\", \"CreatedOn\"),\n",
    "    \"HRMax\": (\"Visit\", \"HRMax\"),\n",
    "    \"Technician\": (\"Visit\", \"Technician\"),\n",
    "    \"Physician\": (\"Visit\", \"Physician\"),\n",
    "    \"ReferringPhysician\": (\"Visit\", \"ReferringPhysician\"),\n",
    "    \"VisitReason\": (\"Visit\", \"VisitReason\"),\n",
    "}\n",
    "\n",
    "# Physiological test categories\n",
    "SPIROMETRY_KEYS = {\n",
    "    \"FVC\", \"FEV1\", \"FEV1/FVC%\", \"FEF25-75%\", \"PEF\", \"FEV1/VCmax%\",\n",
    "    \"MEF25%\", \"MEF50%\", \"MEF75%\"\n",
    "}\n",
    "LUNG_VOLUME_KEYS = {\n",
    "    \"TLC(Pleth)\", \"RV(Pleth)\", \"FRC(Pleth)\", \"RV/TLC(Pleth)\",\n",
    "    \"VC\", \"ERV\", \"IC\"\n",
    "}\n",
    "DIFFUSION_KEYS = {\n",
    "    \"DLCO unadj\", \"DLCO corr\", \"VA\", \"KCO\", \"TLC(DLCO)\", \"DLCO PB\"\n",
    "}\n",
    "\n",
    "# Column formatting helper\n",
    "def format_param_row(p):\n",
    "    return \"{:<18} {:<7} {:<12} {:<7} {:<8} {:<9} {:<7} {:<7}\".format(\n",
    "        p.get(\"Name\", \"\"),\n",
    "        p.get(\"Value\", \"\"),\n",
    "        p.get(\"UM\", \"\"),\n",
    "        p.get(\"Predicted\", \"\"),\n",
    "        p.get(\"PercPred\", \"\"),\n",
    "        p.get(\"ZScore\", \"\"),\n",
    "        p.get(\"LLN\", \"\"),\n",
    "        p.get(\"ULN\", \"\")\n",
    "    )\n",
    "\n",
    "PARAM_HEADER = \"{:<18} {:<7} {:<12} {:<7} {:<8} {:<9} {:<7} {:<7}\".format(\n",
    "    \"Parameter\", \"Value\", \"UM\", \"Pred\", \"%Pred\", \"ZScore\", \"LLN\", \"ULN\"\n",
    ")\n",
    "    \n",
    "def classify_obstruction(params):\n",
    "    \"\"\"Determine GOLD stage based on % predicted FEV1 (assumes FEV1/FVC < 70).\"\"\"\n",
    "    fev1_perc_pred = float(next(p[\"PercPred\"] for p in params if p[\"Name\"] == \"FEV1\"))\n",
    "    if fev1_perc_pred >= 80:\n",
    "        return \"GOLD Stage 1\"\n",
    "    elif fev1_perc_pred >= 50:\n",
    "        return \"GOLD Stage 2\"\n",
    "    elif fev1_perc_pred >= 30:\n",
    "        return \"GOLD Stage 3\"\n",
    "    else:\n",
    "        return \"GOLD Stage 4\"\n",
    "    \n",
    "    \n",
    "GOLD_NOTE = \"\"\"\n",
    "Note:\n",
    "Global Initiative for Chronic Obstructive Lung Disease (GOLD) characterises obstruction as follows:\n",
    "No Obstruction if FEV1/FVC ratio of ‚©æ70%\n",
    "GOLD staging applies if FEV1/FVC <70%, based on ppFEV1:\n",
    "- GOLD Stage 1: ‚©æ80%\n",
    "- GOLD Stage 2: 50‚Äì79%\n",
    "- GOLD Stage 3: 30‚Äì49%\n",
    "- GOLD Stage 4: <30%\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# ========================\n",
    "# MAIN REVIEW LOOP\n",
    "# ========================\n",
    "\n",
    "for json_path in saved_json_paths:\n",
    "    print(f\"\\nüìù Reviewing: {json_path.name}\")\n",
    "\n",
    "    # Load JSON content\n",
    "    with open(json_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    lines = []\n",
    "\n",
    "    # --- VISIT INFORMATION ---\n",
    "    lines.append(\"=== VISIT INFORMATION ===\")\n",
    "    for label, (section, key) in VISIT_FIELDS_MAP.items():\n",
    "        value = data.get(section, {}).get(key)\n",
    "        if value is not None:\n",
    "            lines.append(f\"{label}: {value}\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "    # --- SUBJECT INFORMATION ---\n",
    "    lines.append(\"=== SUBJECT INFORMATION ===\")\n",
    "    for label, (section, key) in SUBJECT_FIELDS_MAP.items():\n",
    "        value = data.get(section, {}).get(key)\n",
    "        if value is not None:\n",
    "            lines.append(f\"{label}: {value}\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "    # --- TEST PARAMETERS ---\n",
    "    grouped_params = {\n",
    "        \"Spirometry\": [],\n",
    "        \"Lung Volumes\": [],\n",
    "        \"Diffusion\": [],\n",
    "        \"Other\": []\n",
    "    }\n",
    "\n",
    "    visit = data.get(\"Visit\", {})\n",
    "    flow_vol_curve = None\n",
    "\n",
    "    for test in visit.get(\"Tests\", []):\n",
    "        for param in test.get(\"Parameters\", []):\n",
    "            name = param.get(\"Name\", \"\")\n",
    "            if name in SPIROMETRY_KEYS:\n",
    "                grouped_params[\"Spirometry\"].append(param)\n",
    "                if name == \"FEV1/FVC%\":\n",
    "                    fev1_fvc = float(param.get(\"Value\", 100))\n",
    "                if name == \"FEV1\":\n",
    "                    fev1_perc_pred = float(param.get(\"PercPred\", 100))\n",
    "            elif name in LUNG_VOLUME_KEYS:\n",
    "                grouped_params[\"Lung Volumes\"].append(param)\n",
    "            elif name in DIFFUSION_KEYS:\n",
    "                grouped_params[\"Diffusion\"].append(param)\n",
    "            else:\n",
    "                grouped_params[\"Other\"].append(param)\n",
    "\n",
    "        # Extract flow-volume curve if present\n",
    "        for gname, gdata in test.get(\"Graphs\", {}).items():\n",
    "            if (\n",
    "                gdata.get(\"X\") == \"V (L)\" and\n",
    "                gdata.get(\"Y\") == \"F (L/s)\" and\n",
    "                gdata.get(\"Points\")\n",
    "            ):\n",
    "                flow_vol_curve = gdata[\"Points\"]\n",
    "                break\n",
    "\n",
    "    # --- DISPLAY PARAMETER TABLES ---\n",
    "    for section, params in grouped_params.items():\n",
    "        if params:\n",
    "            lines.append(f\"--- {section.upper()} ---\")\n",
    "            lines.append(PARAM_HEADER)\n",
    "            for p in params:\n",
    "                lines.append(format_param_row(p))\n",
    "            lines.append(\"\")\n",
    "\n",
    "    # Print formatted report\n",
    "    print(\"\\n\".join(lines))\n",
    "\n",
    "       # --- FLOW-VOLUME PLOT ---\n",
    "    if flow_vol_curve:\n",
    "        vol, flow = zip(*flow_vol_curve)\n",
    "        plt.figure(figsize=(4, 3))\n",
    "        plt.plot(vol, flow)\n",
    "        plt.xlabel(\"Volume (L)\")\n",
    "        plt.ylabel(\"Flow (L/s)\")\n",
    "        plt.title(f\"Flow-Volume Curve: {json_path.stem}\")\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save the plot\n",
    "        plot_filename = f\"{json_path.stem}_flowvol.png\"\n",
    "        plot_path = output_folder / plot_filename\n",
    "        plt.savefig(plot_path)\n",
    "        print(f\"üìä Flow-volume curve saved to: {plot_path}\")\n",
    "\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No flow-volume curve found with X='V (L)' and Y='F (L/s)'.\")\n",
    "    \n",
    "    # Define obstruction for this test\n",
    "    if fev1_fvc > 70:\n",
    "        obstruction_flag = \"No Obstruction\"\n",
    "    else:\n",
    "        obstruction_flag = classify_obstruction(grouped_params[\"Spirometry\"])\n",
    "            \n",
    "\n",
    "    print(f\"The obstruction_flag for this test has been set to: {obstruction_flag}\")\n",
    "    print(GOLD_NOTE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
