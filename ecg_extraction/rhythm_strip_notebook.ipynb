{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92b0c369",
   "metadata": {},
   "source": [
    "# Notebook to extract and digitise a rhythm strip from 12 lead ECGs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9636cef7",
   "metadata": {},
   "source": [
    "## üìÅ Project Structure\n",
    "\n",
    "Organise your working directory like this:  \n",
    "Create a folder ecg_extraction for this bit of the project. \n",
    "\n",
    "ecg_extraction/   \n",
    "‚îú‚îÄ‚îÄ input/            ‚Üí folder for input ECG PDFs.  \n",
    "‚îú‚îÄ‚îÄ output/           ‚Üí folder for processed images, plots, and data.  \n",
    "‚îú‚îÄ‚îÄ requirements.txt  ‚Üí list of packages to install with pip.  \n",
    "‚îî‚îÄ‚îÄ ecg_notebook.ipynb ‚Üí this notebook.  \n",
    "\n",
    "Set your base path as the ecg_extraction folder.  \n",
    "e.g. basepath = /mydocuments/research/ecg_extraction  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172b8f88",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Environment Setup\n",
    "\n",
    "To run this notebook, you can either set up a local Python environment or use Google Colab in your browser.\n",
    "\n",
    "### Option A ‚Äî Local Python Environment (recommended)\n",
    "\n",
    "Use either `venv` or `conda` to isolate your dependencies.  \n",
    "I suggest Python 3.12. \n",
    "\n",
    "#### Using `venv`\n",
    "\n",
    "```bash\n",
    "python3.12 -m venv ecg_env\n",
    "source ecg_env/bin/activate        # On Windows: ecg_env\\Scripts\\activate\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "#### Using `conda`\n",
    "```bash\n",
    "conda create -n ecg_env python=3.11.12\n",
    "conda activate ecg_env\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "Note to self. In my setup I used the 'life' env.   \n",
    "\n",
    "   \n",
    "#### Option B ‚Äî Google Colab (browser-based)  \n",
    "\n",
    "If you don‚Äôt have a local Python setup, you can prototype in Colab.  \n",
    "\t1.\tGo to colab.research.google.com. \n",
    "\t2.\tUpload this notebook and run it in the browser  \n",
    "\t3.\tAt the top of the notebook, add and run:  \n",
    "\n",
    "```bash\n",
    "!pip install numpy pandas matplotlib opencv-python scikit-image scipy pillow pytesseract pdf2image   \n",
    "```  \n",
    "\n",
    "### Remember:  \n",
    "### Use only anonymized ECG data in Colab. Use it for prototyping, development and experimentation.  \n",
    "### Never upload files containing patient names, dates of birth, IDs, or identifiable information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce8bd5a",
   "metadata": {},
   "source": [
    "## üì¶ Required Imports  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae71931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß† Core imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# üñºÔ∏è Image processing\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "# üìê Morphological processing\n",
    "from skimage.morphology import skeletonize\n",
    "\n",
    "# üìä Signal processing\n",
    "from scipy.signal import medfilt, savgol_filter\n",
    "\n",
    "# üî§ OCR  \n",
    "import pytesseract\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0181ff83",
   "metadata": {},
   "source": [
    "## üìÅ Project Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39230416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base directory (where this notebook lives)\n",
    "BASE_PATH = Path.cwd()\n",
    "\n",
    "# Define subfolders for input ECG PDFs and output results\n",
    "INPUT_FOLDER = BASE_PATH / \"input\"\n",
    "PROCESSED_INPUT_FOLDER = INPUT_FOLDER / \"processed_input\"\n",
    "OUTPUT_FOLDER = BASE_PATH / \"output\"\n",
    "\n",
    "# Confirm paths for the student\n",
    "print(\"‚úÖ Paths set:\")\n",
    "print(\"  üìÇ Notebook directory:    \", BASE_PATH)\n",
    "print(\"  üìÇ Input folder:          \", INPUT_FOLDER)\n",
    "print(\"  üìÇ Processed Input folder:\", PROCESSED_INPUT_FOLDER)\n",
    "print(\"  üìÇ Output folder:         \", OUTPUT_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90f3ecf",
   "metadata": {},
   "source": [
    "## üóÇÔ∏è Prepare ECG PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9615447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## üìÑ Scan Input PDFs and Extract ECG Page\n",
    "\n",
    "# Some ECG PDFs contain multiple pages:\n",
    "# - Page 1 is usually a title or cover page\n",
    "# - Page 2 often contains the most recent 12-lead ECG (most relevant for analysis)\n",
    "\n",
    "# This block:\n",
    "# - Converts each PDF into one or more images\n",
    "# - If multi-page, saves page 2 as a PNG\n",
    "# - If single-page, saves page 1 as a PNG\n",
    "# - Outputs are saved to: input/processed_input/\n",
    "# - Files for processing are named as: `pdf_name_raw_pg2.png` or `pdf_name_raw_pg1.png`\n",
    "\n",
    "# Define the processed image output folder\n",
    "PROCESSED_INPUT_FOLDER = INPUT_FOLDER / \"processed_input\"\n",
    "\n",
    "# Find and process all PDFs\n",
    "pdf_files = sorted(INPUT_FOLDER.glob(\"*.pdf\"))\n",
    "print(f\"Found {len(pdf_files)} PDF file(s) in input/\")\n",
    "print(\"The variable 'pdf_files' holds the following file list:\")\n",
    "for file in pdf_files:\n",
    "    print(f\"  ‚ûú {file.name}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "\n",
    "\n",
    "for pdf_path in pdf_files:\n",
    "    pages = convert_from_path(pdf_path, dpi=300)\n",
    "    num_pages = len(pages)\n",
    "    print(f\"{pdf_path.name}: {num_pages} page(s)\")\n",
    "\n",
    "    if num_pages > 1:\n",
    "        selected_page = pages[1]  # page 2\n",
    "        suffix = \"raw_pg2\"\n",
    "    else:\n",
    "        selected_page = pages[0]  # page 1\n",
    "        suffix = \"raw_pg1\"\n",
    "\n",
    "    out_path = PROCESSED_INPUT_FOLDER / f\"{pdf_path.stem}_{suffix}.png\"\n",
    "    selected_page.save(out_path)\n",
    "    print(f\"  ‚ûú Saved: {out_path.name}\")\n",
    "\n",
    "    # Show a 10% size preview of the extracted page\n",
    "    preview = selected_page.resize(\n",
    "        (int(selected_page.width * 0.1), int(selected_page.height * 0.1))\n",
    "    )\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    plt.imshow(preview)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57b78f6",
   "metadata": {},
   "source": [
    "## üü• Detect and Crop Red ECG Grid Box\n",
    "\n",
    "Each processed PNG image contains a full page ECG. We now extract the main red grid box where the waveform is plotted.\n",
    "\n",
    "We define the `find_ecg_grid_box()` function which works as follows:\n",
    "\n",
    "1. Converts the image to HSV color space\n",
    "2. Filters out red-colored pixels using two hue ranges (0‚Äì10 and 160‚Äì180)\n",
    "3. Uses morphological operations to clean the mask\n",
    "4. Finds the largest red contour (assumed to be the ECG grid)\n",
    "5. Crops and returns that bounding box\n",
    "\n",
    "We'll apply this to each file in `input/processed_input/`, save the result to `output/`, and display a 10% preview."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e164f6e",
   "metadata": {},
   "source": [
    "### How `find_ecg_grid_box()` Works\n",
    "\n",
    "This function isolates and crops the red ECG plotting area using:\n",
    "\n",
    "### Libraries Used:\n",
    "- `PIL.Image` + `numpy`: to convert and manipulate image pixel data\n",
    "- `cv2` (OpenCV): for color-space conversion, masking, and contour detection\n",
    "\n",
    "### Key Steps:\n",
    "1. **Convert to HSV color space**  \n",
    "   - HSV makes it easier to isolate color ranges (like \"red\") than RGB\n",
    "\n",
    "2. **Define red hue ranges**  \n",
    "   - ECG grids are often printed in red or pink\n",
    "   - We use two hue bands in HSV:  \n",
    "     - Hue 0‚Äì10 (pure red)  \n",
    "     - Hue 160‚Äì180 (wraparound reds)\n",
    "\n",
    "3. **Create a binary mask of red areas**\n",
    "\n",
    "4. **Clean the mask using morphological closing**  \n",
    "   - Removes small holes and merges nearby grid lines\n",
    "\n",
    "5. **Find contours**  \n",
    "   - We extract all red blobs and assume the largest one is the ECG grid\n",
    "\n",
    "6. **Crop and return the bounding box around the largest red contour**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0ce86b",
   "metadata": {},
   "source": [
    "### What is HSV Color Space?\n",
    "\n",
    "**HSV** stands for:\n",
    "- **H**ue ‚Äì the type of color (e.g., red, green, blue)\n",
    "- **S**aturation ‚Äì the intensity or purity of the color\n",
    "- **V**alue (or brightness) ‚Äì how light or dark the color is\n",
    "\n",
    "While digital images are typically stored in **RGB** (Red, Green, Blue), HSV is often better for image analysis because it separates **color (hue)** from **brightness (value)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75d3d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all PNGs in the processed input folder\n",
    "processed_images = sorted((INPUT_FOLDER / \"processed_input\").glob(\"*.png\"))\n",
    "\n",
    "\n",
    "def find_ecg_grid_box(img):\n",
    "    \"\"\"Extracts the main red ECG box from the image using HSV filtering.\"\"\"\n",
    "    rgb = np.array(img)\n",
    "    hsv = cv2.cvtColor(rgb, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    # Define red hue range in HSV\n",
    "    lower_red1 = np.array([0, 50, 100])\n",
    "    upper_red1 = np.array([10, 255, 255])\n",
    "    lower_red2 = np.array([160, 50, 100])\n",
    "    upper_red2 = np.array([180, 255, 255])\n",
    "\n",
    "    # Create red mask\n",
    "    mask1 = cv2.inRange(hsv, lower_red1, upper_red1)\n",
    "    mask2 = cv2.inRange(hsv, lower_red2, upper_red2)\n",
    "    red_mask = cv2.bitwise_or(mask1, mask2)\n",
    "\n",
    "    # Clean the mask using morphological closing\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    cleaned = cv2.morphologyEx(red_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Find the largest red box\n",
    "    contours, _ = cv2.findContours(cleaned, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        raise RuntimeError(\"No red ECG box found\")\n",
    "\n",
    "    largest = max(contours, key=cv2.contourArea)\n",
    "    x, y, w, h = cv2.boundingRect(largest)\n",
    "\n",
    "    return img.crop((x, y, x + w, y + h))\n",
    "\n",
    "for img_path in processed_images:\n",
    "    try:\n",
    "        # Load image\n",
    "        img = Image.open(img_path)\n",
    "        \n",
    "        # Extract red ECG grid box\n",
    "        ecg_box = find_ecg_grid_box(img)\n",
    "\n",
    "        # Save extracted box to output/ with _grid suffix\n",
    "        out_path = OUTPUT_FOLDER / f\"{img_path.stem.replace('_raw_', '_grid_')}.png\"\n",
    "        ecg_box.save(out_path)\n",
    "        print(f\"Saved ECG grid: {out_path.name}\")\n",
    "\n",
    "        # Show a preview (resized)\n",
    "        preview = ecg_box.resize((int(ecg_box.width * 0.1), int(ecg_box.height * 0.1)))\n",
    "        plt.figure(figsize=(6, 3))\n",
    "        plt.imshow(preview)\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Could not process {img_path.name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21886e0",
   "metadata": {},
   "source": [
    "## üìâ Extract Rhythm Strip from ECG Grid\n",
    "\n",
    "In this step:\n",
    "- We divide the ECG grid vertically into 6 equal-height segments\n",
    "- We extract **only the 5th segment** (zero-indexed as row 4)\n",
    "\n",
    "Our 12-lead ECG appear to be divided into **6 horizontal rows**:\n",
    "\n",
    "| Row | Content                             |\n",
    "|-----|-------------------------------------|\n",
    "| 1   | Leads I, II, III                    |\n",
    "| 2   | Leads aVR, aVL, aVF                 |\n",
    "| 3   | Leads V1, V2, V3                    |\n",
    "| 4   | Leads V4, V5, V6                    |\n",
    "| 5   | **Lead II rhythm strip** (long)     |\n",
    "| 6   | **V5 rhythm strip** (long, optional)|\n",
    "\n",
    "\n",
    "You could extend the code later to also extract **row 6** (V5 rhythm) if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efd6a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_rhythm_strip_from_box(box_img, panel_index=4, total_panels=6):\n",
    "    \"\"\"\n",
    "    Extract a specific horizontal panel from the ECG grid.\n",
    "    Default is row 5 (panel_index=4) which contains the Lead II rhythm strip.\n",
    "    \"\"\"\n",
    "    w, h = box_img.size\n",
    "    panel_height = h // total_panels\n",
    "    y0 = panel_index * panel_height\n",
    "    y1 = (panel_index + 1) * panel_height\n",
    "    return box_img.crop((0, y0, w, y1))\n",
    "\n",
    "# Process all grid images saved earlier\n",
    "grid_images = sorted(OUTPUT_FOLDER.glob(\"*_grid_*.png\"))\n",
    "print(f\"Found {len(grid_images)} ECG grid image(s) to process for rhythm strip.\")\n",
    "\n",
    "for img_path in grid_images:\n",
    "    try:\n",
    "        grid_img = Image.open(img_path)\n",
    "        rhythm_strip = extract_rhythm_strip_from_box(grid_img, panel_index=4)\n",
    "\n",
    "        # Save with _strip_ in filename\n",
    "        out_path = OUTPUT_FOLDER / f\"{img_path.stem.replace('_grid_', '_strip_')}.png\"\n",
    "        rhythm_strip.save(out_path)\n",
    "\n",
    "        print(f\"Saved rhythm strip to: {out_path.relative_to(BASE_PATH)}\")\n",
    "\n",
    "        # 10% preview\n",
    "        preview = rhythm_strip.resize((\n",
    "            int(rhythm_strip.width * 0.1),\n",
    "            int(rhythm_strip.height * 0.1)\n",
    "        ))\n",
    "        plt.figure(figsize=(6, 3))\n",
    "        plt.imshow(preview)\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting from {img_path.name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9701d582",
   "metadata": {},
   "source": [
    "## üß† Digitize ECG Trace (Black on White + X:Y Coordinates)\n",
    "\n",
    "This step:\n",
    "- Removes the red grid and background from the extracted rhythm strip\n",
    "- Inverts the image to get a **black trace on white background**\n",
    "- Extracts the (x, y) coordinates of the darkest part of the signal at each column\n",
    "- Saves:\n",
    "  - The binarized image as `*_digitized.png`\n",
    "  - The coordinates as `*_trace.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d81272",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def digitize_ecg_trace(strip_img_path, output_folder):\n",
    "    \"\"\"\n",
    "    Given a rhythm strip image path, this function:\n",
    "    - Masks the red grid/background\n",
    "    - Isolates the trace\n",
    "    - Inverts for black-on-white\n",
    "    - Extracts (x, y) coordinates\n",
    "    - Saves both image and .csv trace\n",
    "    \"\"\"\n",
    "    base = strip_img_path.stem.replace(\"_strip_\", \"\")\n",
    "    save_image_path = output_folder / f\"{base}_digitized.png\"\n",
    "    save_csv_path = output_folder / f\"{base}_trace.csv\"\n",
    "\n",
    "    # Step 1: Load and convert to HSV\n",
    "    rgb = np.array(Image.open(strip_img_path))\n",
    "    hsv = cv2.cvtColor(rgb, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    # Define red regions\n",
    "    lower_red1 = np.array([0, 50, 100])\n",
    "    upper_red1 = np.array([10, 255, 255])\n",
    "    lower_red2 = np.array([160, 50, 100])\n",
    "    upper_red2 = np.array([180, 255, 255])\n",
    "    red_mask1 = cv2.inRange(hsv, lower_red1, upper_red1)\n",
    "    red_mask2 = cv2.inRange(hsv, lower_red2, upper_red2)\n",
    "    full_red_mask = cv2.bitwise_or(red_mask1, red_mask2)\n",
    "\n",
    "    # Invert red mask, keep dark non-red areas\n",
    "    non_red = cv2.bitwise_not(full_red_mask)\n",
    "    v = hsv[:, :, 2]\n",
    "    dark = (v < 90).astype(np.uint8) * 255\n",
    "    trace_mask = cv2.bitwise_and(non_red, dark)\n",
    "\n",
    "    # Binarize and invert: black trace, white background\n",
    "    trace_binary = (trace_mask > 0).astype(np.uint8) * 255\n",
    "    trace_inverted = 255 - trace_binary\n",
    "\n",
    "    # Save image\n",
    "    Image.fromarray(trace_inverted).save(save_image_path)\n",
    "    print(f\"üñºÔ∏è Saved digitized trace image: {save_image_path.relative_to(BASE_PATH)}\")\n",
    "\n",
    "    # Step 2: Extract (x, y) coordinates\n",
    "    ys, xs = np.where(trace_inverted < 128)\n",
    "    df_trace = pd.DataFrame({'x_pixel': xs, 'y_pixel': ys})\n",
    "    trace = df_trace.groupby('x_pixel')['y_pixel'].min()\n",
    "\n",
    "    # Save coordinates\n",
    "    trace_df = trace.reset_index()\n",
    "    trace_df.columns = ['x_pixel', 'y_pixel']\n",
    "    trace_df.to_csv(save_csv_path, index=False)\n",
    "    print(f\"üìà Saved trace coordinates to: {save_csv_path.relative_to(BASE_PATH)}\")\n",
    "\n",
    "    # Preview\n",
    "    plt.figure(figsize=(12, 2))\n",
    "    plt.plot(trace.index, trace.values, color='black', linewidth=0.8)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.xlabel(\"x (pixels)\")\n",
    "    plt.ylabel(\"y (pixels)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return trace_df\n",
    "\n",
    "# Apply to all _strip_ images\n",
    "strip_imgs = sorted(OUTPUT_FOLDER.glob(\"*_strip_*.png\"))\n",
    "print(f\"üéØ Found {len(strip_imgs)} rhythm strip image(s) to digitize.\")\n",
    "\n",
    "for strip_path in strip_imgs:\n",
    "    try:\n",
    "        digitize_ecg_trace(strip_path, OUTPUT_FOLDER)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Failed to digitize {strip_path.name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c678a9",
   "metadata": {},
   "source": [
    "## üß† Learning Panel: Understanding ECG Calibration\n",
    "\n",
    "When ECGs are digitized from paper or scanned files, the pixel values represent the signal, but these pixels must be translated into real physiological units: **milliseconds (ms)** for time and **millivolts (mV)** for voltage.  \n",
    "Every standard ECG begins with a **calibration pulse** ‚Äì usually 1 mV in height and 250 ms in width ‚Äì to serve as a reference for interpreting amplitudes and durations.  \n",
    "The calibration is printed on the ECG and is usually as in this case but not always 25mm/s and 10mm/mV. The sampling frequency of the ECG machine is also provided ie 150Hz.   \n",
    "In the grid one small box is 1mm square. One large box is 5mm x 5mm.  \n",
    "This script walks through how we **automatically detect and interpret the calibration pulse** using only the digitized trace stored in a CSV file.  \n",
    "We will then be able to calculate a pixel to mV and pixel to ms ratio and transform the trace to physiological units.  \n",
    "In production we will save this new trace as new columns 'x_ms' and 'y_mv' in our csv file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288e348a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÇ Step 1: Select a sample digitized ECG trace from the output folder\n",
    "# We pick the first _trace.csv file as an example\n",
    "trace_files = sorted(OUTPUT_FOLDER.glob(\"*_trace.csv\"))\n",
    "csv_path = trace_files[0]  # Just for demo ‚Äì we don't modify this file\n",
    "df_trace = pd.read_csv(csv_path)\n",
    "\n",
    "# üõ†Ô∏è Step 2: Clean and standardize the column names\n",
    "df_trace.columns = df_trace.columns.str.strip().str.lower()\n",
    "\n",
    "# üîç Step 3: Analyze the calibration pulse at the start of the trace\n",
    "def analyze_calibration_pulse(df_trace, x_max=100, flat_tol=1):\n",
    "    \"\"\"\n",
    "    Estimate calibration pulse height and width from digitized trace.\n",
    "\n",
    "    Parameters:\n",
    "        df_trace (pd.DataFrame): DataFrame with 'x_pixel' and 'y_pixel' columns\n",
    "        x_max (int): Only consider first x_max horizontal pixels (where pulse appears)\n",
    "        flat_tol (int): Acceptable variation in y-pixels for the flat top\n",
    "\n",
    "    Returns:\n",
    "        dict: Pixel measurements and pulse boundary positions\n",
    "    \"\"\"\n",
    "\n",
    "    # ü™Ñ Logic: Look only at the leftmost part of the trace (the calibration pulse appears at the start)\n",
    "    df = df_trace[df_trace['x_pixel'] < x_max].copy()\n",
    "\n",
    "    # üß± Step 3a: The pulse has a flat \"top\" ‚Äì we find its most common y-value\n",
    "    top_y = df['y_pixel'].mode()[0]\n",
    "    \n",
    "    # üìè Define the flat-top region of the pulse using a tolerance (e.g. ¬±1 pixel)\n",
    "    flat_top = df[(df['y_pixel'] >= top_y - flat_tol) & (df['y_pixel'] <= top_y + flat_tol)]\n",
    "    if flat_top.empty:\n",
    "        raise ValueError(\"No flat region detected at pulse top\")\n",
    "\n",
    "    # ‚è±Ô∏è Step 3b: Extract horizontal extent of the pulse (for duration)\n",
    "    start_x = flat_top['x_pixel'].min()\n",
    "    end_x = flat_top['x_pixel'].max()\n",
    "\n",
    "    # üîç Step 3c: Estimate vertical baseline from flat region before the upstroke\n",
    "    pre_pulse = df[df['x_pixel'] < start_x]\n",
    "    window = pre_pulse[pre_pulse['x_pixel'] > start_x - 10]  # e.g. 10 pixels before\n",
    "\n",
    "    if window.empty:\n",
    "        raise ValueError(\"No data found before the pulse to estimate baseline.\")\n",
    "\n",
    "    # Optional: filter within tolerance of the mode to ensure stability\n",
    "    baseline_mode = window['y_pixel'].mode()[0]\n",
    "    stable_baseline = window[np.abs(window['y_pixel'] - baseline_mode) <= 1]\n",
    "\n",
    "    # Final baseline value\n",
    "    base_y = stable_baseline['y_pixel'].median() if not stable_baseline.empty else window['y_pixel'].median()\n",
    "\n",
    "    # üßÆ Compute pulse height and width in pixels\n",
    "    height = base_y - top_y\n",
    "    width = end_x - start_x\n",
    "\n",
    "    # üñºÔ∏è Plot of the calibration pulse showing detection landmarks\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(df['x_pixel'], df['y_pixel'], label=\"Trace\", color='black')\n",
    "    plt.axvspan(start_x, end_x, color='orange', alpha=0.2, label=\"Flat top region\")\n",
    "    plt.axhline(top_y, color='blue', linestyle='--', label=\"Top Y (plateau)\")\n",
    "    plt.axhline(base_y, color='red', linestyle='--', label=\"Base Y (baseline)\")\n",
    "    plt.gca().invert_yaxis()  # Flip y-axis to match ECG appearance\n",
    "    plt.xlabel(\"x (pixels)\")\n",
    "    plt.ylabel(\"y (pixels)\")\n",
    "    plt.title(\"Calibration Pulse Characterization\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # üìå Note:\n",
    "    # From the image, the upstroke of the calibration pulse is NEARLY vertical.\n",
    "    # In our test file, it deviates by only ~1 pixel.\n",
    "    # This is likely a digitization artifact from rasterization, binarization, or line thickness.\n",
    "    # It's not clinically meaningful and does not affect the pulse calibration.\n",
    "\n",
    "    print(f\"üìè Pulse width: {width} px (‚Üí 250 ms)\")\n",
    "    print(f\"üìê Pulse height: {height} px (‚Üí 1 mV)\")\n",
    "\n",
    "    return {\n",
    "        'height_px': height,\n",
    "        'width_px': width,\n",
    "        'start_x': start_x,\n",
    "        'end_x': end_x,\n",
    "        'top_y': top_y,\n",
    "        'base_y': base_y,\n",
    "    }\n",
    "\n",
    "# üìä Step 4: Run the calibration analysis\n",
    "# Print the digitised trace with physiological units\n",
    "calibration_info = analyze_calibration_pulse(df_trace)\n",
    "\n",
    "# ‚úÖ Summary:\n",
    "# - We have detected a calibration pulse in the first ~100 pixels of the trace\n",
    "# - The vertical height corresponds to 1 mV\n",
    "# - The horizontal width corresponds to 250 ms\n",
    "# - This provides the scaling to convert pixel units into real ECG units (mV and ms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd48cc53",
   "metadata": {},
   "source": [
    "## üèÅ Final Processing.  \n",
    "### Print and save correctly Calibrated & Scaled Rhythm Strip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69943ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Analyze calibration pulse ---\n",
    "def analyze_calibration_pulse(df_trace, x_max=100, flat_tol=1):\n",
    "    \"\"\"\n",
    "    Analyze the calibration pulse at the start of a digitized ECG trace.\n",
    "\n",
    "    Parameters:\n",
    "        df_trace (pd.DataFrame): ECG trace with 'x_pixel' and 'y_pixel' columns\n",
    "        x_max (int): Only analyze first x_max horizontal pixels\n",
    "        flat_tol (int): Tolerance in y-pixels for identifying the flat-top\n",
    "\n",
    "    Returns:\n",
    "        dict: Pulse geometry and boundaries\n",
    "    \"\"\"\n",
    "    df = df_trace[df_trace['x_pixel'] < x_max].copy()\n",
    "\n",
    "    top_y = df['y_pixel'].mode()[0]\n",
    "    flat_top = df[(df['y_pixel'] >= top_y - flat_tol) & (df['y_pixel'] <= top_y + flat_tol)]\n",
    "    if flat_top.empty:\n",
    "        raise ValueError(\"No flat region detected at pulse top\")\n",
    "\n",
    "    start_x = flat_top['x_pixel'].min()\n",
    "    end_x = flat_top['x_pixel'].max()\n",
    "\n",
    "    # Baseline from short stable segment before upstroke\n",
    "    window = df[df['x_pixel'].between(start_x - 10, start_x - 1)]\n",
    "    if window.empty:\n",
    "        raise ValueError(\"No baseline segment found before calibration pulse\")\n",
    "\n",
    "    baseline_mode = window['y_pixel'].mode()[0]\n",
    "    stable_baseline = window[abs(window['y_pixel'] - baseline_mode) <= 1]\n",
    "    base_y = stable_baseline['y_pixel'].median() if not stable_baseline.empty else window['y_pixel'].median()\n",
    "\n",
    "    height = base_y - top_y\n",
    "    width = end_x - start_x\n",
    "\n",
    "    print(f\"üìè Pulse width: {width} px (‚Üí 250 ms)\")\n",
    "    print(f\"üìê Pulse height: {height} px (‚Üí 1 mV)\")\n",
    "\n",
    "    return {\n",
    "        'height_px': height,\n",
    "        'width_px': width,\n",
    "        'start_x': start_x,\n",
    "        'end_x': end_x,\n",
    "        'top_y': top_y,\n",
    "        'base_y': base_y,\n",
    "    }\n",
    "\n",
    "# --- Plot calibrated ECG ---\n",
    "def plot_calibrated_trace(df, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot calibrated ECG trace using time (ms) and voltage (mV).\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Must contain 'x_ms' and 'y_mv'\n",
    "        save_path (Path): Optional PNG path to save the plot\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 2))\n",
    "    plt.plot(df['x_ms'], df['y_mv'], color='black', linewidth=0.8)\n",
    "    plt.xlabel(\"Time (ms)\")\n",
    "    plt.ylabel(\"Voltage (mV)\")\n",
    "    plt.title(\"Digitized Lead II ECG (Calibrated)\")\n",
    "    plt.xticks(ticks=range(0, int(df['x_ms'].max()) + 1000, 1000))\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "        print(f\"üñºÔ∏è Saved calibrated plot: {save_path.name}\")\n",
    "    plt.show()\n",
    "\n",
    "# --- Process all trace files ---\n",
    "trace_files = sorted(OUTPUT_FOLDER.glob(\"*_trace.csv\"))\n",
    "print(f\"üöÄ Found {len(trace_files)} file(s) to calibrate.\")\n",
    "\n",
    "for csv_path in trace_files:\n",
    "    try:\n",
    "        print(f\"\\nüìÑ Processing: {csv_path.name}\")\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        # Expecting x_pixel, y_pixel from digitizer\n",
    "        cal = analyze_calibration_pulse(df)\n",
    "\n",
    "        px_per_mv = cal['height_px']\n",
    "        px_per_ms = cal['width_px'] / 250  # 250 ms standard\n",
    "\n",
    "        df['x_ms'] = df['x_pixel'] / px_per_ms\n",
    "        df['y_mv'] = -(df['y_pixel'] - cal['base_y']) / px_per_mv\n",
    "\n",
    "        # Save calibrated CSV\n",
    "        calibrated_csv = csv_path.with_name(csv_path.stem + \"_calibrated.csv\")\n",
    "        df[['x_pixel', 'y_pixel', 'x_ms', 'y_mv']].to_csv(calibrated_csv, index=False)\n",
    "        print(f\"‚úÖ Calibrated CSV saved: {calibrated_csv.name}\")\n",
    "\n",
    "        # Save plot\n",
    "        plot_path = csv_path.with_name(csv_path.stem + \"_calibrated.png\")\n",
    "        plot_calibrated_trace(df, save_path=plot_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to process {csv_path.name}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "life",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
